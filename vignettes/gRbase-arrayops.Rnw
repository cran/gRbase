%\VignetteIndexEntry{gRbase-arrayops: Array operations in gRbase}
%\VignettePackage{gRbase}

\documentclass[10pt]{article}
%\usepackage[T1]{fontenc}
\usepackage[latin1]{inputenc}
%\usepackage{inputenx}
\usepackage{boxedminipage,color,a4wide,url}

\def\code#1{\texttt{#1}}
\def\R{\texttt{R}}
\def\pkg#1{\texttt{#1}}

\def\grain{\texttt{gRain}}
\def\grbase{\texttt{gRbase}}
\def\ptab{\code{ptab}}

\usepackage{fancyvrb}

\newlength{\fancyvrbtopsep}
\newlength{\fancyvrbpartopsep}
\makeatletter
\FV@AddToHook{\FV@ListParameterHook}{\topsep=\fancyvrbtopsep\partopsep=\fancyvrbpartopsep}
\makeatother

\setlength{\fancyvrbtopsep}{0pt}
\setlength{\fancyvrbpartopsep}{0pt}

\SweaveOpts{keep.source=T}

<<echo=FALSE,print=FALSE>>=
require( gRbase )
prettyVersion <- packageDescription("gRbase")$Version
prettyDate <- format(Sys.Date())
@

\title{Array operations in the \grbase\ package}
\author{S{\o}ren H{\o}jsgaard}
\date{\pkg{gRbase} version \Sexpr{prettyVersion} as of \Sexpr{prettyDate}}


\begin{document}

%%\SweaveInput{Rmarkup.STY}

\definecolor{darkred}{rgb}{.7,0,0}
\definecolor{midnightblue}{rgb}{0.098,0.098,0.439}

\DefineVerbatimEnvironment{Sinput}{Verbatim}{
  fontfamily=tt,
  %%fontseries=b,
  %% xleftmargin=2em,
  formatcom={\color{midnightblue}}
}
\DefineVerbatimEnvironment{Soutput}{Verbatim}{
  fontfamily=tt,
  %%fontseries=b,
  %% xleftmargin=2em,
  formatcom={\color{darkred}}
}
\DefineVerbatimEnvironment{Scode}{Verbatim}{
  fontfamily=tt,
  %%fontseries=b,
  %% xleftmargin=2em,
  formatcom={\color{blue}}
}

\fvset{listparameters={\setlength{\topsep}{-2pt}}}
\renewenvironment{Schunk}{\linespread{.80}}{}



\maketitle

\parindent0pt\parskip5pt

\tableofcontents

@
<<echo=F>>=
##library(gRbase)
options("width"=100)
options(useFancyQuotes="UTF-8")
@ %def


\section{Introduction}

This note describes some operations on arrays in \R. These operations
have been implemented to facilitate implementation of graphical models
and Bayesian networks in R.

\section{Arrays/tables in \R}
\label{sec:arrays}

The documentation of \R\ states the following about arrays:

\begin{quote}
  \em
  An array in R can have one, two or more dimensions. It is simply a
  vector which is stored with additional attributes giving the
  dimensions (attribute "dim") and optionally names for those
  dimensions (attribute "dimnames").

  A two-dimensional array is the same thing as a matrix.

  One-dimensional arrays often look like vectors, but may be handled
  differently by some functions.
\end{quote}

Hence the defining characterstic of an array is that it is a vector
with a dim attribute. For example
@
<<>>=
## 1-dimensional array
x1 <- 1:8
dim(x1) <- 8
x1
c(is.array(x1), is.matrix(x1))

## 2-dimensional array (matrix)
x2 <- 1:8
dim(x2) <- c(2,4)
x2
c(is.array(x2), is.matrix(x2))

## 3-dimensional array
x3 <- 1:8
dim(x3) <- c(2,2,2)
x3
c(is.array(x3), is.matrix(x3))
@ %def



Notice that arrays do not need a \code{dimnames} attribute. However,
for some of the operations described in the following, \code{dimnames}
are essential.

Next consider the \code{lizard} data in \grbase:

@
<<>>=
data( lizard, package="gRbase" )
lizard
@ %def

Data has \code{dim} and \code{dimnames} attributes (and the list of
\verb'dimnames' has names; this is important):
@
<<>>=
dim( lizard )
dimnames(lizard)
@ %def
Notice from the output above that the first variable (\code{diam})
varies fastest.

We can subset arrays in different ways:
@
<<>>=
## because lizard is a vector
lizard[1:2]
## because lizard is an array
lizard[,1,1]
## useful if subsetting programatically
margin <- 2:3; level <- c(1,1)
z <- as.list(rep(TRUE,3))
z[margin] <- level
str(z)
do.call("[", c(list(lizard), z))
@ %def
It is worth noticing that the result is not necessarily an array:
@
<<>>=
is.array( lizard[1:2] )
is.array( lizard[,1,1] )
is.array( lizard[,1,] )
@ %def




\section{Operations on tables}

Consider again the \verb'lizard' data
In the following we shall denote the dimnames (or variables) by $D$,
$H$ and $S$ and we let $(d,h,s)$ denote a configuration of these
variables. The contingency table above shall be denoted by $T_{DHS}$
and we shall refer to the $(d,h,s)$ entry as $T_{DHS}(d,h,s)$.

@
<<>>=
T.DHS <- lizard
@ %def

\subsection{Marginal tables}
\label{sec:marginal-tables}

The $DS$--marginal table $T_{DS}$ is defined to be the table with
values
\begin{displaymath}
  T_{DS}(d,s) = \sum_h T_{DHS}(d,h,s)
\end{displaymath}
In \R:
@
<<>>=
T.DS <- tabMarg(lizard, ~diam+species); T.DS
## Alternative forms
T.DS <- tabMarg(lizard, c("diam","species"))
T.DS <- tabMarg(lizard, c(1,3))
@ %def

@
<<echo=F,results=hide>>=
T.DS <- tableMargin(lizard, ~diam+species); T.DS
T.HS <- tableMargin(lizard, ~height+species); T.HS
@ %def

\subsection{Permuting a table}
\label{sec:permuting-table}

A reorganization of the table can be made with \code{tabPerm}:

@
<<>>=
T.SHD <- tabPerm(T.DHS, ~species+height+diam); ftable( T.SHD )
## Alternative forms:
T.SHD <- tabPerm(T.DHS, c("species","height","diam"))
T.SHD <- tabPerm(T.DHS, c(3,2,1))
T.SHD <- aperm(T.DHS, c(3,2,1))
@ %def


\subsection{Slice of a table}
\label{sec:slice-table}

A slice of a table is obtained with \code{tabSlice}:

@
<<>>=
tabSlice(lizard, slice=list(species="anoli"))
@ %def

\subsection{Operations on two tables: $+$, $-$, $*$, $/$}
\label{sec:oper-two-tabl}

The product of two tables, e.g. $T_{DS}$ and $T_{HS}$ is defined to be
the table $\tilde T_{DHS}$ with entries
\begin{displaymath}
  \tilde T_{DHS}(d,h,s)= T_{DS}(d,s) T_{HS}(h,s)
\end{displaymath}

In \R:
@
<<>>=
T.HS <- tabMarg(lizard, ~height+species)
T.DHS.mult = tabMult( T.DS, T.HS )
ftable( T.DHS.mult )
@ %def

%% @
%% <<echo=F,results=hide>>=
%% microbenchmark::microbenchmark(
%%     tabMult__( T.DS, T.HS ), arrayOp( T.DS, T.HS ) )
%% @ %def


The quotient, sum and difference is defined similarly:
@
<<>>=
T.DHS.div  = tabDiv( T.DS, T.HS )
T.DHS.add  = tabAdd( T.DS, T.HS )
T.DHS.subt = tabSubt( T.DS, T.HS )
@ %def


%% @
%% <<>>=
%% ftable( tablePerm(T.DHS, c("species","height","diam")) )
%% @ %def

\subsection{Miscellaneous}
\label{sec:miscellaneous}


Consider this way of ``blowing up'' an array with extra dimensions.
@
<<>>=
T.HSD2 <- tabExpand(T.DS, T.HS); T.HSD2
names(dimnames(T.HSD2))
@ %def

Here \verb'T.HSD2' is a $3$--way table with the same variable names as
the union of the variable names in \verb'T.DS' and \verb'T.HS'. Those
variables in those variables in \verb'T.HS' vary fastest. Lastly, if
we regards \verb'T.HSD2' as a function of $(h,s,d)$ we see that
\verb'T.HSD2' is constant as a function of $s$.

Next, \code{tabAlign()} will allign the first array to have the same
variable order as the second array:
@
<<>>=
tabAlign(T.SHD, T.DHS)
@ %def

An also be achieved as
@
<<>>=
n.new <- names(dimnames(T.DHS)); n.new
n.old <- names(dimnames(T.SHD)); n.old
if (setequal( n.new, n.old )){
    tabPerm( T.SHD, n.new )
} else {
    numeric(0)
}
@ %def


Next we consider comparisons of arrays:
@
<<>>=
tabEqual( T.SHD, T.DHS )
@ %def
These two tables are defined to be identical because after a
permutation of the first table we end up with a table with varable names
(in the same order) as the second table and the elements. The elements
are numerically identical.



\section{Defining tables / arrays}
%%\label{sec:xx}

As mentioned above, a table can be represented as an array. In general,
arrays do not need dimnames in \R, but for the functions described
here, the dimnames are essential. We shall just notice that in
addition to \code{array()}, a an array can also be defined using
\code{parray()} from \grbase. For example
@
<<>>=
yn <- c("y","n")
T.AB <- array(c(5,95,1,99), dim=c(2,2), dimnames=list("A"=yn, "B"=yn))
T.AB <- parray(c("A","B"), levels=list(yn, yn), values=c(5,95,1,99))
@ %def

Using \code{parray()}, arrays can be normalized in two ways:
Normalization can be over the first variable for \emph{each}
configuration of all other variables or over all configurations. For
example:

@
<<print=T>>=
T.AB <- parray(c("A","B"), levels=list(yn, yn), values=c(5,95,1,99),
               normalize="first")
T.AB <- parray(c("A","B"), levels=list(yn, yn), values=c(5,95,1,99),
               normalize="all")
@ %def



\section{Example: A Bayesian network}
\label{sec:comp-with-arrays}

A classical example of a Bayesian network is the ``sprinkler
example'', see e.g.\
\url{http://en.wikipedia.org/wiki/Bayesian_network}:
\begin{quote}
  \em
  Suppose that there are two events which could cause grass to be wet:
  either the sprinkler is on or it is raining. Also, suppose that the
  rain has a direct effect on the use of the sprinkler (namely that
  when it rains, the sprinkler is usually not turned on). Then the
  situation can be modeled with a Bayesian network.
\end{quote}

@
<<>>=
r <- parray("rain", levels=list(yn), values=c(.2, .8))
s.r <- parray(c("sprinkler","rain"), levels=list(yn,yn),
              values=c(.01, .99, .4, .6))
w.sr <- parray(c("wet","sprinkler","rain"), list(yn,yn,yn),
               values=c(.99, .01, .8, .2, .9, .1, 0, 1))
r
s.r
ftable(w.sr, col.vars = "wet")
@ %def




The joint distribution can be obtained in different ways:
@
<<>>=
joint <- tabMult( tabMult(r, s.r), w.sr )
ftable(joint)
## Alternative
joint <- tabListMult( list( r, s.r, w.sr ) )
@ %def


What is the probability that it rains given that the grass is wet?
@
<<>>=
wr.marg <- tabMarg(joint, ~wet+rain); wr.marg
tabDiv( wr.marg, tabMarg(wr.marg, ~wet))
## Alternative -- and shorter
tabCondProb(wr.marg, cond=~wet)
@ %def

Alternative computation
@
<<>>=
x <- tabSliceMult(wr.marg, slice=list(wet="y")); x
tabMarg(x, ~rain)
tabCondProb( tabMarg(x, ~rain) )
@ %def




\section{Example: Iterative Proportional Scaling (IPS)}
\label{sec:ips}

Consider the two factor log--linear model for the \verb'lizard'
data. Under the model the expected counts have the form
\begin{displaymath}
  \log m(d,h,s)= a_1(d,h)+a_2(d,s)+a_3(h,s)
\end{displaymath}
If we let $n(d,h,s)$ denote the observed counts, the likelihood
equations are: Find $m(d,h,s)$ such that
\begin{displaymath}
  m(d,h)=n(d,h), \quad
  m(d,s)=n(d,s), \quad
  m(h,s)=n(h,s)
\end{displaymath}

The updates are as follows: For the first term we have
\begin{displaymath}
  m(d,h,s) \leftarrow m(d,h,s) \frac{n(d,h)}{m(d,h)}, \mbox{ where }
  m(d,h) = \sum_s m(d,h,s)
\end{displaymath}




A rudimentary implementation of iterative proportional scaling for
log--linear models is straight forward:
@
<<>>=
myips <- function(indata, glist){
    fit   <- indata
    fit[] <-  1
    ## List of sufficient marginal tables
    md    <- lapply(glist, function(g) tabMarg(indata, g))

    for (i in 1:4){
        for (j in seq_along(glist)){
            mf  <- tabMarg(fit, glist[[j]])
            adj <- tabDiv( md[[j]], mf)
            fit <- tabMult( fit, adj )
        }
    }
    pearson=sum( (fit-indata)^2 / fit)
    pearson
}

glist<-list(c("species","diam"),c("species","height"),c("diam","height"))
str( myips(lizard, glist), max.level=2)
str( loglin(lizard, glist), max.level = 2)
@ %def






\section{Some low level functions}
\label{sec:some-low-level}

As an example we take the following:

@
<<>>=
dim2222 <- c(2,2,2,2)
dim2323 <- c(2,3,2,3)
@ %def

\subsection{\code{cell2entry()} and \code{entry2cell()}}


The map from a cell to the corresponding
entry is provided by \code{cell2entry()}. The reverse operation, going
from an entry to a cell (which is much less needed) is provided by
\code {entry2cell()}.

@
<<>>=
cell2entry(c(1,1,1,1), dim2222)
entry2cell(1, dim2222)
cell2entry(c(2,1,2,1), dim2222)
entry2cell(6, dim2222)
@ %def





% @
% <<eval=F,echo=F>>=
% cell2entry2(c(2,1,2,1), dim)
% cell2entryR(c(2,1,2,1), dim)
% @ %def




\subsection{\code{nextCell()} and \code{nextCellSlice()}}
%\label{sec:x}

Given a cell, say $i=(1,1,2,1)$ we often want to find the next cell in
the table following the convention that the first factor varies
fastest, that is $(2,1,2,1)$. This is provided by
\code{nextCell()}.

@
<<>>=
nextCell(c(1,1,2,1), dim2222)
nextCell(c(2,2,2,1), dim2222)
@ %def


Given $A\subset \Delta$ and a cell $i_A \in I_A$ consider the cells
$I(i_A)=\{j\in I|j_A = i_A\}$. For example, the cells satisfying that
dimension $2$ is at level $1$. Given such a cell, say $(2,1,1,2)$ we
often want to find the next cell also satisfying this constraint
(again following the convention that the first factor varies fastest),
that is $(1,1,2,2)$. This is provided by \code{nextCellSlice()}.
@
<<>>=
nextCellSlice(c(2,1,1,2),  sliceset=2, dim2323)
nextCellSlice(c(1,3,2,1),  sliceset=c(2,3), dim2323)
@ %def




\subsection{\code{slice2entry()}}
%\label{sec:x}

Given $A\subset \Delta$ and a cell $i_A \in I_A$. This cell defines a
slice of the original array, namely the cells
$I(i_A)=\{j\in I|j_A = i_A\}$.
We often want to find the entries in
$x$ for the cells $I(i_A)$. This is provided by
\code{slice2entry()}. For example, we may want the entries for
the cells $(*,1,2,*)$ or $(2,2,*,*)$:

@
<<>>=
r1<-slice2entry(slicecell=c(1,2), sliceset=c(2,3), dim2222); r1
@ %def

To verify that we indeed get the right cells:

@
<<>>=
do.call(rbind, lapply(r1, entry2cell, dim2222))
@ %def



\subsection{\code{permuteCellEntries()}}

In a $2\times 3$ table, entries $1,\dots,6$ correspond to combinations
$(1,1),(2,1),(1,2),(2,2),(1,3),(2,3)$. If we permute the table to a $3
\times 2$ table the entries become as follows:

@
<<>>=
p<-permuteCellEntries(perm=c(2,1), dim=c(2,3)); p
@ %def

So for example,

@
<<>>=
(A <- array(11:16, dim=c(2,3)))
Ap <- A[p]
dim(Ap) <- c(3,2)
Ap
@ %def

This corresponds to

@
<<>>=
aperm(A, c(2,1))
@ %def


% \section{\code{aperm()}}





\subsection{\code{factGrid()} -- Factorial grid}
\label{sec:factgrid}

Using the operations above we can obtain the combinations of the
factors as a matrix:

@
<<>>=
ff <- factGrid(dim2222)
head(ff, 4)
tail(ff, 4)
@ %def

This is the same as (but faster)

@
<<>>=
aa <- expand.grid(list(1:2,1:2,1:2,1:2))
head(aa, 4)
@ %def

There is a slice version as well:
@
<<>>=
factGrid(dim2222, slicecell=c(1,2), sliceset=c(2,3))
@ %def




\end{document}
